{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "UNoOfc2JM3un"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#COMP 760 Generative Modeling Assignment"
      ],
      "metadata": {
        "id": "LzrTbgsDLDkM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Please place your full name here:**"
      ],
      "metadata": {
        "id": "PvZLRkkWMg3n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Purpose\n",
        "\n",
        "This assignment is intended to assess your ability to:\n",
        "\n",
        "- Implement a Fully Connected Autoencoder\n",
        "- Implement a Convolutional Autoencoder\n",
        "- Understand the Variational Autoencoder intuition\n",
        "\n",
        "## Task:\n",
        "\n",
        "In this assignment, you will design and implement a Fully-Connected and a CNN Autoencoder. With a simple change in your Fully-Connected Autoencoder, you will become more familiar with Variational Autoencoders.\n",
        "\n",
        "You will complete the following tasks in a Jupyter Notebook with Python and Keras (please use the [functional API Model](https://keras.io/guides/functional_api/). Do not use the sequential model.) https://keras.io/api/ is a nice reference to the Keras APIs.\n",
        "\n",
        "Studying the program examples in Ch. 3 from the text book can be very helpful.\n",
        "\n",
        "**DataSet**: You will work with  the MNIST handwritten digit dataset. It has 60,000 28x28 grayscale images of the 10 digits, along with a test set of 10,000 images.\n",
        "\n",
        "There are three tasks and one optional (bonus) task.\n",
        "Please complete the tasks by writing Python code in the designated cells. Please add comments to help the instructor understand your code.\n",
        "Some code and utility functions have been provided.\n",
        "\n",
        "Put your resspones to the questions in a separate Word document."
      ],
      "metadata": {
        "id": "K-lFRiwbKxuo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Preparation"
      ],
      "metadata": {
        "id": "qlmPk3ndM9RM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Imports"
      ],
      "metadata": {
        "id": "2M4TSh24Bie6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRKOhGz12F0k"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras import layers, models, optimizers, utils, datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Utility function"
      ],
      "metadata": {
        "id": "0CzqpMWUlX6d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#display images\n",
        "import matplotlib.pyplot as plt\n",
        "def display2(\n",
        "    images, n=10, size=(20, 4), cmap=\"gray_r\", as_type=\"float32\", shape=(28,28)\n",
        "):\n",
        "    \"\"\"\n",
        "    Displays n random images from each one of the supplied arrays.\n",
        "    \"\"\"\n",
        "    # n:How many digits we will display\n",
        "    plt.figure(figsize=size)\n",
        "    for i in range(n):\n",
        "        ax = plt.subplot(2, n, i + 1)\n",
        "        # Reshape the image to the right size based on the shape argument\n",
        "        plt.imshow(images[i].astype(as_type).reshape(shape), cmap=cmap)\n",
        "        #plt.gray()\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gDY-8m40Pa-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Load training data\n"
      ],
      "metadata": {
        "id": "Q94euywXlfDy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load training data in Google Colab\n",
        "from keras.datasets import mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "assert x_train.shape == (60000, 28, 28)"
      ],
      "metadata": {
        "id": "ns5NnIy8PcTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you can see some images corretly displayed, the dataset would have been loaded sauccesfully."
      ],
      "metadata": {
        "id": "GDyoUrWoB7wo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSOi2em62F0q"
      },
      "outputs": [],
      "source": [
        "# display 10 random images\n",
        "display2(x_train)\n",
        "# check the image dataset shape\n",
        "print(x_train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preprocess data\n",
        "In the following preprocess function, we take into account that in order to train the model, we have to convert `uint8` data to `float32` and normalize the pixel values to [0, 1]. Pay attention to how each image is padded to 32 x 32 for easier manipulation of the tensor shape as it passes through the network."
      ],
      "metadata": {
        "id": "rWRiKvypHUti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the data\n",
        "def preprocess(imgs):\n",
        "    \"\"\"\n",
        "    Normalize and reshape the images\n",
        "    \"\"\"\n",
        "    # normalize all values between 0 and 1 and pad image to 32x32\n",
        "    imgs = imgs.astype(\"float32\") / 255.0\n",
        "    imgs = np.pad(imgs, ((0, 0), (2, 2), (2, 2)), constant_values=0.0)\n",
        "    imgs = np.expand_dims(imgs, -1)\n",
        "\n",
        "    imgs = imgs.reshape((len(imgs), np.prod(imgs.shape[1:]))) # flatten the image\n",
        "    return imgs\n",
        "\n",
        "x_train = preprocess(x_train)\n",
        "x_test = preprocess(x_test)\n",
        "\n",
        "#check the image dataset shape\n",
        "print(x_train.shape)\n",
        "# display 10 randome images\n",
        "display2(x_train, shape=(32,32))"
      ],
      "metadata": {
        "id": "JHDpXswqHWt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Task 1 (15 points):\n",
        "\n",
        "Implement a Fully-Connected Autoencoder in Keras with these layers: Input, Dense. The encoder and decoder should include one or more layers, with the size chosen by you. Your Autoencoder should have a bottleneck with two neurons and `mean_squared_error` (MSE) as the loss function to begin with.\n",
        "\n",
        "The model can be created by using `keras.Model` to group the layers. Next, set your optimizer, loss function and compile your model (keras.compile).\n",
        "Train your model with the training set. Randomly select 10 images from the test set, encode them and visualize the decoded images.\n",
        "Try to change your autoencoder, e.g. increase the bottleneck size, add more layers, use the `binary_crossentropy` loss function. Compare the loss values and reconstructed images."
      ],
      "metadata": {
        "id": "wX92KKWiBddb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.1 Buid the encoder"
      ],
      "metadata": {
        "id": "8BdL4FBXazss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder"
      ],
      "metadata": {
        "id": "PPtYMsgYa136"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####1.2 Build the decoder"
      ],
      "metadata": {
        "id": "RO-ICt_MbK9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Decoder"
      ],
      "metadata": {
        "id": "RsKK8jxUbNiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####1.3 Build the autoencoder"
      ],
      "metadata": {
        "id": "EfIV8dIIbkoz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Autoencoder"
      ],
      "metadata": {
        "id": "2CwiTo6iblPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.4 Train the autoencoder"
      ],
      "metadata": {
        "id": "xQLpU-8Sbzz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile and train the autoencoder\n"
      ],
      "metadata": {
        "id": "sNFA5hRJb1oh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.5 Reconstruct some images using the autoencoder"
      ],
      "metadata": {
        "id": "gzRdgLgccadH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reconstruct some images"
      ],
      "metadata": {
        "id": "qOrP6tyjccEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 2 (15 points):\n",
        "Implement a Convolutional Autoencoder (CAE) that uses only the following types of layers: convolution, pooling, upsampling and transpose. Use `mean_squared_error`. The encoder and decoder should include one or more layers, with the size and number of filters chosen by you. Start with a bottleneck of size 2, train your model on MNIST. Randomly select 10 images from the test set, encode them and visualize the decoded images. Are the reconstructed images readable for humans? If not, try to some different architectures for your CAE, including a larger bottleneck, that is powerful enough to generate readable images. The bottleneck should be as small as possible for readability. Try more layers and use the `binary_crossentropy` loss function."
      ],
      "metadata": {
        "id": "qe8RWb5SMENY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1 Build the encoder"
      ],
      "metadata": {
        "id": "FD-IBS1xJNyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder"
      ],
      "metadata": {
        "id": "Q9Wb7GWOJWx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####2.2 Build the decoder"
      ],
      "metadata": {
        "id": "pgKeWIccJztp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Decoder"
      ],
      "metadata": {
        "id": "R3Xt8thxMYGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####2.3 Build the autoencoder"
      ],
      "metadata": {
        "id": "fKKbMCVZJ2rW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Autoencoder"
      ],
      "metadata": {
        "id": "WbtYkPAYJ4yv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####2.4 Train the autoencoder"
      ],
      "metadata": {
        "id": "krwJH-KxJ5Zy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile and train the autoencoder"
      ],
      "metadata": {
        "id": "XUc8EjR_KAMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.5 Reconstruct some images using the autoencoder"
      ],
      "metadata": {
        "id": "DDqihUmAKAov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reconstruct some images"
      ],
      "metadata": {
        "id": "_elWGcmmJ_9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Task 3 (20 points):\n",
        "This question is about using an Autoencoder to generate similar but not identical hand-written digits. We use a naive approach: Try to see if a trained decoder can map randomly generated inputs (random numbers) to a recognizable hand-written digit.\n",
        "\n",
        "Start with your Fully-Connected and trained Autoencoder from Task 1. Try to generate new images by inputting some random numbers to the decoder (i.e. the bottleneck layer) and report your results. Hint: This is not easy. You probably want to input at least 10 random numbers.\n",
        "\n",
        "Now restrict the Autoencoder hidden bottleneck layer(s) to have a standard multi-variate normal distribution (https://numpy.org/doc/stable/reference/random/generated/numpy.random.multivariate_normal.html) with mean zeroes and the identity matrix as variance (i.e. no correlations). An identity matrix is a square matrix having 1s on the main diagonal, and 0s everywhere else.\n",
        "\n",
        "For example:\n",
        "$\n",
        "\\begin{bmatrix}\n",
        "    1 & 0 & 0 & 0 \\\\\n",
        "    0 & 1 & 0 & 0 \\\\\n",
        "    0 & 0 & 1 & 0 \\\\\n",
        "    0 & 0 & 0 & 1\n",
        " \\end{bmatrix}\n",
        "$\n",
        "\n",
        "Retrain the Fully-Connected Autoencoder with the normalized bottleneck. Now randomly generate inputs to the bottleneck layer that are drawn from the multi-variate standard normal distribution, and use the random inputs to generate new images. Report your result.\n",
        "\n",
        "Are the output images different between Tasks 1 and 2? If so, why do you think this difference occurs?"
      ],
      "metadata": {
        "id": "mXY_hVvoMYqJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####3.1 The encoder\n",
        "Restrict the hidden bottleneck layer(s) to have a standard multi-variate normal distribution"
      ],
      "metadata": {
        "id": "MKMwjh05KW8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code for this task"
      ],
      "metadata": {
        "id": "E_8iwTbuKWSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####3.2 The decoder"
      ],
      "metadata": {
        "id": "pWyjFSrHKaVA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code for this task"
      ],
      "metadata": {
        "id": "HPQx8QK2KcK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####3.3 The autoencoder"
      ],
      "metadata": {
        "id": "Iim9_k_mKdAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code for this task"
      ],
      "metadata": {
        "id": "EuWdVE2MKfyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####3.3 Train your new autoencoder"
      ],
      "metadata": {
        "id": "yEr0UvelGXPY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code for this task"
      ],
      "metadata": {
        "id": "5hV5rGaqM3FU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.4 Generate some new images"
      ],
      "metadata": {
        "id": "XjAzAcMlF5mu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code for this task"
      ],
      "metadata": {
        "id": "tFG5uSZkGWuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Submission\n",
        "\n",
        "Your notebook should include the final code and results. Your exploations and answers to the questions should be in a separate Word document.\n",
        "\n",
        "Download ( rename as: `firstname_lastname_comp670_gm.ipynb`) and submit your notebook along with the Word document on Canvas Assignment: Generative Modeling, by the due date."
      ],
      "metadata": {
        "id": "zubt5qSfNCpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optional Task 4 (15 points)\n",
        "Change the Autoencoder which you developed in the last part of Task 3 so that it becomes a Variational Autoencoder (refer to our lecture and the textbook Ch. 3). Does the VAE produce a different quality of output image?\n"
      ],
      "metadata": {
        "id": "UNoOfc2JM3un"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code for Task 4:"
      ],
      "metadata": {
        "id": "fr--zbPDOD8A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}